{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will read the tokens from tokenized_complete.txt, perform sentiment analysis on each token, and write the results to sentiment_results.txt. Each line in sentiment_results.txt will be a dictionary representing the sentiment scores of a token.Please note that this is a very basic example. The SentimentIntensityAnalyzer is more effective when used on larger pieces of text (like sentences or paragraphs) rather than individual tokens. Also, this code assumes that your tokens are separated by spaces. If your tokens are separated by something else, youâ€™ll need to modify the split() function accordingly. \n",
    "\n",
    "import nltk, csv\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Initialize novel_name to None\n",
    "novel_name = None\n",
    "\n",
    "# Define a regex pattern for the novel titles\n",
    "pattern = re.compile(r'\\[(\\w+)\\]')\n",
    "\n",
    "# Open the input file\n",
    "with open('../output/merged_titles.txt', 'r') as f:\n",
    "    # Iterate over each line in the file\n",
    "    for line in f:\n",
    "        # Remove leading/trailing whitespace\n",
    "        line = line.strip()\n",
    "        # If the line is a novel title (matches the regex pattern)\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            # If a novel has been processed, perform sentiment analysis on its entire text\n",
    "            if novel_name:\n",
    "                sentiment = sia.polarity_scores(' '.join(results[novel_name]))\n",
    "                results[novel_name] = sentiment\n",
    "            # Extract the new novel name and initialize its results list\n",
    "            novel_name = match.group(1)\n",
    "            results[novel_name] = []\n",
    "        # If the line is part of a novel\n",
    "        elif novel_name:\n",
    "            # Add the line to the novel's results list\n",
    "            results[novel_name].append(line)\n",
    "\n",
    "# If a novel has been processed, perform sentiment analysis on its entire text\n",
    "if novel_name:\n",
    "    sentiment = sia.polarity_scores(' '.join(results[novel_name]))\n",
    "    results[novel_name] = sentiment\n",
    "\n",
    "# Open the output file\n",
    "with open('../output/merged_sentiment_results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the headers to the file\n",
    "    writer.writerow(['novel_name', 'neg', 'neu', 'pos', 'compound'])\n",
    "    # Iterate over each novel and its results\n",
    "    for novel_name, sentiment in results.items():\n",
    "        # Write the novel name and sentiment result to the file\n",
    "        writer.writerow([novel_name] + list(sentiment.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jamessmithies/Library/CloudStorage/Dropbox/Technical/datascience/found-infrastructure/standalone_compute/nltk/nltk-sentiment-analysis.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamessmithies/Library/CloudStorage/Dropbox/Technical/datascience/found-infrastructure/standalone_compute/nltk/nltk-sentiment-analysis.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, x)\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, x) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamessmithies/Library/CloudStorage/Dropbox/Technical/datascience/found-infrastructure/standalone_compute/nltk/nltk-sentiment-analysis.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Calculate average sentiment\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jamessmithies/Library/CloudStorage/Dropbox/Technical/datascience/found-infrastructure/standalone_compute/nltk/nltk-sentiment-analysis.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m average_sentiment \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamessmithies/Library/CloudStorage/Dropbox/Technical/datascience/found-infrastructure/standalone_compute/nltk/nltk-sentiment-analysis.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Plot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamessmithies/Library/CloudStorage/Dropbox/Technical/datascience/found-infrastructure/standalone_compute/nltk/nltk-sentiment-analysis.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[39m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[39m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn not found: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key]\u001b[39m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: 1'"
     ]
    }
   ],
   "source": [
    "# Visualise the results: Import necessary libraries (pandas, matplotlib); Load the `merged_sentiment_results.txt` file into a pandas DataFrame; Extract the novel titles using the provided regex and add them as a new column in the DataFrame; Calculate the average sentiment for each novel; Plot the average sentiment for each novel using a bar chart or line graph.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../output/merged_sentiment_results.csv', sep=\"\\t\", header=None)\n",
    "\n",
    "# Extract novel titles\n",
    "df['title'] = df[0].apply(lambda x: re.search(r'\\[(\\w+)\\]', x).group(1) if re.search(r'\\[(\\w+)\\]', x) else '')\n",
    "\n",
    "# Calculate average sentiment\n",
    "average_sentiment = df.groupby('title')[1].mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "average_sentiment.plot(kind='bar')\n",
    "plt.ylabel('Average Sentiment')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
